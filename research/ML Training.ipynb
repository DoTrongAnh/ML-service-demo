{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, Embedding, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Income classifier\n",
    "Using a dataset of people's personal information to determine their likely income, as in whether or not they manage to earn more than 50K anually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country income  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40           Cuba  <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/pplonski/datasets-for-start/master/adult/data.csv',\n",
    "                skipinitialspace=True)\n",
    "x_cols = [c for c in df.columns if c != 'income']\n",
    "X = df[x_cols]\n",
    "y = df['income']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 31.0, 'workclass': 'Private', 'fnlwgt': 121124, 'education': 'HS-grad', 'education-num': 9.0, 'marital-status': 'Married-civ-spouse', 'occupation': 'Prof-specialty', 'relationship': 'Husband', 'race': 'White', 'sex': 'Male', 'capital-gain': 0.0, 'capital-loss': 0.0, 'hours-per-week': 40.0, 'native-country': 'United-States'}\n"
     ]
    }
   ],
   "source": [
    "train_mode = dict(X_train.mode().iloc[0])\n",
    "X_train = X_train.fillna(train_mode)\n",
    "print (train_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = {}\n",
    "for col in ['workclass','education','marital-status','occupation','relationship','race','sex','native-country']:\n",
    "    cat_convert = LabelEncoder()\n",
    "    X_train[col] = cat_convert.fit_transform(X_train[col])\n",
    "    encoder[col] = cat_convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100).fit(X_train, y_train)\n",
    "et = ExtraTreesClassifier(n_estimators=100).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./extra_trees.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(train_mode, \"./train_mode.joblib\", compress=True)\n",
    "joblib.dump(encoder, \"./encoders.joblib\", compress=True)\n",
    "joblib.dump(rf, \"./random_forest.joblib\", compress=True)\n",
    "joblib.dump(et, \"./extra_trees.joblib\", compress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Premium Insurance\n",
    "Using a dataset of people's medical records to determine the likeliest premium insurance prices (in indian rupees) they will have to pay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>BloodPressureProblems</th>\n",
       "      <th>AnyTransplants</th>\n",
       "      <th>AnyChronicDiseases</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>KnownAllergies</th>\n",
       "      <th>HistoryOfCancerInFamily</th>\n",
       "      <th>NumberOfMajorSurgeries</th>\n",
       "      <th>PremiumPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>183</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>28000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Diabetes  BloodPressureProblems  AnyTransplants  AnyChronicDiseases  \\\n",
       "0   45         0                      0               0                   0   \n",
       "1   60         1                      0               0                   0   \n",
       "2   36         1                      1               0                   0   \n",
       "3   52         1                      1               0                   1   \n",
       "4   38         0                      0               0                   1   \n",
       "\n",
       "   Height  Weight  KnownAllergies  HistoryOfCancerInFamily  \\\n",
       "0     155      57               0                        0   \n",
       "1     180      73               0                        0   \n",
       "2     158      59               0                        0   \n",
       "3     183      93               0                        0   \n",
       "4     166      88               0                        0   \n",
       "\n",
       "   NumberOfMajorSurgeries  PremiumPrice  \n",
       "0                       0         25000  \n",
       "1                       0         29000  \n",
       "2                       1         23000  \n",
       "3                       2         28000  \n",
       "4                       1         23000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Medicalpremium.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(986, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Age': 45.0, 'Diabetes': 0.0, 'BloodPressureProblems': 0.0, 'AnyTransplants': 0.0, 'AnyChronicDiseases': 0.0, 'Height': 174.0, 'Weight': 70.0, 'KnownAllergies': 0.0, 'HistoryOfCancerInFamily': 0.0, 'NumberOfMajorSurgeries': 0.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)\n",
    "train_mode = dict(X_train.mode().iloc[0])\n",
    "X_train = X_train.fillna(train_mode)\n",
    "print (train_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier accuracy: 0.8956521739130435\n",
      "SVC accuracy: 0.8028985507246377\n",
      "DecisionTreeClassifier accuracy: 0.8782608695652174\n",
      "LogisticRegression accuracy: 0.7333333333333334\n",
      "SGDClassifier accuracy: 0.2753623188405797\n",
      "GaussianNB accuracy: 0.21449275362318837\n",
      "KNeighborsClassifier accuracy: 0.5840579710144927\n",
      "MLPClassifier accuracy: 0.7333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "n_train = int(len(X)*0.7)\n",
    "classifiers = [RandomForestClassifier(),\n",
    "               SVC(kernel='linear'),\n",
    "               DecisionTreeClassifier(),\n",
    "               LogisticRegression(solver=\"liblinear\", max_iter=100),\n",
    "               SGDClassifier(),\n",
    "              GaussianNB(),\n",
    "              KNeighborsClassifier(),\n",
    "              MLPClassifier()]\n",
    "\n",
    "for model in classifiers:\n",
    "    print(\"{} accuracy: {}\".format(model.__class__.__name__, cross_val_score(model, X_train, y_train, scoring=\"accuracy\").mean()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./pi_decision_tree.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier().fit(X_train, y_train)\n",
    "dt = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "joblib.dump(train_mode, \"./pi_train_mode.joblib\", compress=True)\n",
    "joblib.dump(rf, \"./pi_random_forest.joblib\", compress=True)\n",
    "joblib.dump(dt, \"./pi_decision_tree.joblib\", compress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Machine translation\n",
    "Using two sets of equivalent sentences in English and French respectively to train model to translate English into French."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137863 137863\n"
     ]
    }
   ],
   "source": [
    "english_sentences = []\n",
    "french_sentences = []\n",
    "with open(\"small_vocab_en.txt\") as entext:\n",
    "    for s in entext:\n",
    "        english_sentences += [s]\n",
    "with open(\"small_vocab_fr.txt\", encoding='utf-8') as frtext:\n",
    "    for s in frtext:\n",
    "        french_sentences += [s]\n",
    "print(len(english_sentences), len(french_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small_vocab_en Line 6:  she is the kindest of little sisters , and I am proud of her .\n",
      "\n",
      "small_vocab_fr Line 6:  elle est la plus gentille des petites sœurs, et je suis fier d'elle .\n",
      "\n",
      "small_vocab_en Line 7:  his favorite food is eggs , but he has no appetite for it at the moment .\n",
      "\n",
      "small_vocab_fr Line 7:  sa nourriture préférée est les œufs , mais il n'a pas d'appétit pour ça .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sample_i in range(5,7):\n",
    "    print('small_vocab_en Line {}:  {}'.format(sample_i + 1, english_sentences[sample_i]))\n",
    "    print('small_vocab_fr Line {}:  {}'.format(sample_i + 1, french_sentences[sample_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1823294 English words.\n",
      "245 unique English words.\n",
      "10 Most common words in the English dataset:\n",
      "\"is\" \",\" \".\" \"in\" \"it\" \"during\" \"the\" \"but\" \"and\" \"sometimes\"\n",
      "\n",
      "1961336 French words.\n",
      "373 unique French words.\n",
      "10 Most common words in the French dataset:\n",
      "\"est\" \".\" \",\" \"en\" \"il\" \"les\" \"mais\" \"et\" \"la\" \"parfois\"\n"
     ]
    }
   ],
   "source": [
    "english_words_counter = collections.Counter([word for sentence in english_sentences for word in sentence.split()])\n",
    "french_words_counter = collections.Counter([word for sentence in french_sentences for word in sentence.split()])\n",
    "print('{} English words.'.format(len([word for sentence in english_sentences for word in sentence.split()])))\n",
    "print('{} unique English words.'.format(len(english_words_counter)))\n",
    "print('10 Most common words in the English dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*english_words_counter.most_common(10)))[0]) + '\"')\n",
    "print()\n",
    "print('{} French words.'.format(len([word for sentence in french_sentences for word in sentence.split()])))\n",
    "print('{} unique French words.'.format(len(french_words_counter)))\n",
    "print('10 Most common words in the French dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*french_words_counter.most_common(10)))[0]) + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max English sentence length: 15\n",
      "Max French sentence length: 21\n",
      "English vocabulary size: 216\n",
      "French vocabulary size: 362\n"
     ]
    }
   ],
   "source": [
    "def tokenize(x):\n",
    "    x_tk = Tokenizer(char_level = False)\n",
    "    x_tk.fit_on_texts(x)\n",
    "    return x_tk.texts_to_sequences(x), x_tk\n",
    "\n",
    "def pad(x, length=None):\n",
    "    if length is None:\n",
    "        length = max([len(sentence) for sentence in x])\n",
    "    return pad_sequences(x, maxlen = length, padding='post')\n",
    "\n",
    "def preprocess(x, y):\n",
    "    x_pre, x_tk = tokenize(x)\n",
    "    y_pre, y_tk = tokenize(y)\n",
    "    x_pre = pad(x_pre)\n",
    "    y_pre = pad(y_pre)\n",
    "    y_pre = y_pre.reshape(*y_pre.shape, 1)\n",
    "    return x_pre, y_pre, x_tk, y_tk\n",
    "\n",
    "en_pre, fr_pre, en_tk, fr_tk = preprocess(english_sentences, french_sentences)\n",
    "print(\"Max English sentence length:\", en_pre.shape[1])\n",
    "print(\"Max French sentence length:\", fr_pre.shape[1])\n",
    "print(\"English vocabulary size:\", len(en_tk.word_index))\n",
    "print(\"French vocabulary size:\", len(fr_tk.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 15, 128)           27776     \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 512)               592896    \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 21, 512)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 21, 512)           1182720   \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 21, 363)           186219    \n",
      "=================================================================\n",
      "Total params: 1,989,611\n",
      "Trainable params: 1,989,611\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def logits_to_text(logits, tokenizer):\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>'\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
    "\n",
    "def custom_model(input_shape, output_len=fr_pre.shape[1], en_vocab_size=len(en_tk.word_index)+1, fr_vocab_size=len(fr_tk.word_index)+1, learning_rate=0.005):\n",
    "    input_layer = Input(shape=(input_shape[1],))\n",
    "    x = Embedding(en_vocab_size, 128)(input_layer)\n",
    "    x = Bidirectional(GRU(256, return_sequences=False))(x)\n",
    "    x = RepeatVector(output_len)(x)\n",
    "    x = Bidirectional(GRU(256, return_sequences=True))(x)\n",
    "    x = TimeDistributed(Dense(fr_vocab_size, activation=\"softmax\"))(x)\n",
    "    model = tf.keras.models.Model(inputs=input_layer, outputs=x)\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tmp_x = pad(en_pre)\n",
    "model = custom_model(tmp_x.shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/17\n",
      "108/108 [==============================] - 819s 7s/step - loss: 2.0183 - accuracy: 0.5391 - val_loss: 1.2318 - val_accuracy: 0.6703\n",
      "Epoch 2/17\n",
      "108/108 [==============================] - 830s 8s/step - loss: 0.9586 - accuracy: 0.7299 - val_loss: 0.6931 - val_accuracy: 0.7944\n",
      "Epoch 3/17\n",
      "108/108 [==============================] - 855s 8s/step - loss: 0.5299 - accuracy: 0.8417 - val_loss: 0.3693 - val_accuracy: 0.8888\n",
      "Epoch 4/17\n",
      "108/108 [==============================] - 872s 8s/step - loss: 0.2846 - accuracy: 0.9168 - val_loss: 0.2472 - val_accuracy: 0.9281\n",
      "Epoch 5/17\n",
      "108/108 [==============================] - 880s 8s/step - loss: 0.1864 - accuracy: 0.9460 - val_loss: 0.1811 - val_accuracy: 0.9479\n",
      "Epoch 6/17\n",
      "108/108 [==============================] - 861s 8s/step - loss: 0.1449 - accuracy: 0.9576 - val_loss: 0.1346 - val_accuracy: 0.9596\n",
      "Epoch 7/17\n",
      "108/108 [==============================] - 867s 8s/step - loss: 0.1326 - accuracy: 0.9605 - val_loss: 0.1985 - val_accuracy: 0.9400\n",
      "Epoch 8/17\n",
      "108/108 [==============================] - 872s 8s/step - loss: 0.1297 - accuracy: 0.9616 - val_loss: 0.1233 - val_accuracy: 0.9631\n",
      "Epoch 9/17\n",
      "108/108 [==============================] - 869s 8s/step - loss: 0.1197 - accuracy: 0.9641 - val_loss: 0.1197 - val_accuracy: 0.9640\n",
      "Epoch 10/17\n",
      "108/108 [==============================] - 877s 8s/step - loss: 0.0884 - accuracy: 0.9739 - val_loss: 0.0950 - val_accuracy: 0.9724\n",
      "Epoch 11/17\n",
      "108/108 [==============================] - 866s 8s/step - loss: 0.0630 - accuracy: 0.9815 - val_loss: 0.0746 - val_accuracy: 0.9784\n",
      "Epoch 12/17\n",
      "108/108 [==============================] - 890s 8s/step - loss: 0.0566 - accuracy: 0.9833 - val_loss: 0.0758 - val_accuracy: 0.9781\n",
      "Epoch 13/17\n",
      "108/108 [==============================] - 867s 8s/step - loss: 0.0616 - accuracy: 0.9818 - val_loss: 0.0894 - val_accuracy: 0.9743\n",
      "Epoch 14/17\n",
      "108/108 [==============================] - 870s 8s/step - loss: 0.0583 - accuracy: 0.9828 - val_loss: 0.1011 - val_accuracy: 0.9705\n",
      "Epoch 15/17\n",
      "108/108 [==============================] - 860s 8s/step - loss: 0.0521 - accuracy: 0.9845 - val_loss: 0.0733 - val_accuracy: 0.9800\n",
      "Epoch 16/17\n",
      "108/108 [==============================] - 851s 8s/step - loss: 0.0385 - accuracy: 0.9888 - val_loss: 0.0927 - val_accuracy: 0.9740\n",
      "Epoch 17/17\n",
      "108/108 [==============================] - 879s 8s/step - loss: 0.0472 - accuracy: 0.9860 - val_loss: 0.0728 - val_accuracy: 0.9802\n",
      "Sample 1:\n",
      "il a vu un vieux camion jaune <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Il a vu un vieux camion jaune\n",
      "Sample 2:\n",
      "new jersey est parfois calme pendant l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "new jersey est parfois calme pendant l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "tmp_X = pad(en_pre)\n",
    "model = custom_model(tmp_X.shape)\n",
    "def final_predictions(x, y, x_tk, y_tk):\n",
    "    \n",
    "    model.fit(tmp_X, fr_pre, batch_size = 1024, epochs = 17, validation_split = 0.2)\n",
    " \n",
    "    y_id_to_word = {value: key for key, value in y_tk.word_index.items()}\n",
    "    y_id_to_word[0] = '<PAD>'\n",
    "    sentence = 'he saw a old yellow truck'\n",
    "    sentence = [x_tk.word_index[word] for word in sentence.split()]\n",
    "    sentence = pad_sequences([sentence], maxlen=x.shape[-1], padding='post')\n",
    "    sentences = np.array([sentence[0], x[0]])\n",
    "    predictions = model.predict(sentences, len(sentences))\n",
    "    print('Sample 1:')\n",
    "    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[0]]))\n",
    "    print('Il a vu un vieux camion jaune')\n",
    "    print('Sample 2:')\n",
    "    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[1]]))\n",
    "    print(' '.join([y_id_to_word[np.max(x)] for x in y[0]]))\n",
    "    \n",
    "final_predictions(en_pre, fr_pre, en_tk, fr_tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_7_layer_call_and_return_conditional_losses, gru_cell_7_layer_call_fn, gru_cell_8_layer_call_and_return_conditional_losses, gru_cell_8_layer_call_fn, gru_cell_10_layer_call_and_return_conditional_losses while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: en_fr_translator\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: en_fr_translator\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"en_fr_translator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 26, 127, 100, 111, 112, 101,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'he saw a old yellow truck'\n",
    "sentence = [en_tk.word_index[word] for word in sentence.split()]\n",
    "sentence = pad_sequences([sentence], maxlen=en_pre.shape[-1], padding='post')\n",
    "sentences = np.array([sentence[0], en_pre[0]])\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./mtprocessor.joblib']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MTProcessor:\n",
    "    def __init__(self, lang_from, lang_tk, target_tk):\n",
    "        self.dict = lang_from\n",
    "        self.token = lang_tk\n",
    "        self.target = target_tk\n",
    "        \n",
    "    def preprocess(self, data):\n",
    "        data = [self.token.word_index[word] if word in self.token.word_index else 0 for word in data.split() if word in self.token.word_index]\n",
    "        data = pad_sequences([data], maxlen=self.dict.shape[-1], padding='post')\n",
    "        return data\n",
    "    \n",
    "    def postprocess(self, data):\n",
    "        y_id = {value: key for key, value in self.target.word_index.items()}\n",
    "        y_id[0] = ' '\n",
    "        return ' '.join([y_id[np.argmax(x)] for x in data]).strip()\n",
    "    \n",
    "processor = MTProcessor(en_pre, en_tk, fr_tk)\n",
    "joblib.dump(processor, './mtprocessor.joblib', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "djangoenv",
   "language": "python",
   "name": "djangoenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
